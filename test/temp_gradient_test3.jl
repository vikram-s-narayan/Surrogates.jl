using Surrogates
using Zygote
using Optim
using ForwardDiff

function vector_of_tuples_to_matrix(v)
    #convert training data generated by surrogate sampling into a matrix suitable for GEKPLS
    num_rows = length(v)
    num_cols = length(first(v))
    K = zeros(num_rows, num_cols)
    for row in 1:num_rows
        for col in 1:num_cols
            K[row, col] = v[row][col]
        end
    end
    return K
end

function vector_of_tuples_to_matrix2(v)
    #convert gradients into matrix form
    num_rows = length(v)
    num_cols = length(first(first(v)))
    K = zeros(num_rows, num_cols)
    for row in 1:num_rows
        for col in 1:num_cols
            K[row, col] = v[row][1][col]
        end
    end
    return K
end

function sphere_function(x)
    return sum(x .^ 2)
end

n = 50
d = 3
lb = [-10.0 for i in 1:d]
ub = [10.0 for i in 1:3]
x = sample(n, lb, ub, SobolSample())
X = vector_of_tuples_to_matrix(x)
grads = vector_of_tuples_to_matrix2(gradient.(sphere_function, x))
y = reshape(sphere_function.(x), (size(x, 1), 1))
xlimits = hcat(lb, ub)

n_test = 20
x_test = sample(n_test, lb, ub, GoldenSample())
X_test = vector_of_tuples_to_matrix(x_test)
y_true = sphere_function.(x_test)
n_comp = 2
delta_x = 0.0001
extra_points = 2
initial_theta = [0.01 for i in 1:n_comp]

g = GEKPLS(X, y, grads, n_comp, delta_x, xlimits, extra_points, initial_theta)
# gradient(g, [1.0 1.0 1.0])
# ForwardDiff.gradient(g, [1.0 1.0 1.0]) 

function min_rlfv(theta)
    g = GEKPLS(X, y, grads, n_comp, delta_x, xlimits, extra_points, theta)
    return -g.reduced_likelihood_function_value
end

Zygote.gradient(min_rlfv, [0.01, 0.1]) #need adjoint error


